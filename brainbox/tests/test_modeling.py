import unittest
import numpy as np
import pandas as pd
import brainbox.modeling.utils as mut

from copy import deepcopy
from scipy.interpolate import interp1d

import brainbox.modeling.linear as lm
import brainbox.modeling.poisson as pm
import brainbox.modeling.design_matrix as dm

# Ugly as hell, but these are necessary parameters for synthetic data. I didn't want to
# make all of the generation functions class methods because that's very ugly for things that
# don't need to be methods.

NTRIALS = 5000  # Number of trials of spiking to simulate
BINSIZE = 0.02
KERNLEN = 0.6
NBASES = 10
LINEAR_KERN_SCALE = 4
GAIN = 15

rng = np.random.default_rng(seed=0b01101001 + 0b01100010 + 0b01101100)

rt_vals = np.array([0.20748797, 0.39415191, 0.58081585, 0.76747979, 0.95414373,
                    1.14080767, 1.32747161, 1.51413555, 1.70079949, 1.88746343])
rt_probs = np.array([0.15970962, 0.50635209, 0.18693285, 0.0707804, 0.02540835,
                     0.01633394, 0.00907441, 0.00725953, 0.00544465, 0.01270417])
contrastvals = [0, 0.0625, 0.125, 0.25, 1.]
bases = mut.full_rcos(KERNLEN, NBASES, lambda x: np.ceil(x / BINSIZE).astype(int))


class TestModels(unittest.TestCase):

    def setUp(self):
        """
        Set up synthetic data of spikes generated by a multiple kernels for GLM to fit for
        later tests of kernel recovery
        """

        vartypes = {'trial_start': 'timing',
                    'stimOn_times': 'timing',
                    'feedback_times': 'timing',
                    'feedback_type': 'value',
                    'bias': 'value', 'bias_next': 'value',
                    'contrasts': 'value', 
                    'trial_end': 'timing'}
        bases = mut.full_rcos(KERNLEN, NBASES, lambda t: np.ceil(t / BINSIZE).astype(int))

        def stepfunc_bias(row):
            currvec = np.ones(design.binf(row.feedback_times)) * row.bias
            nextvec = np.ones(design.binf(row.duration) - design.binf(row.feedback_times)) *\
                row.bias_next
            return np.hstack((currvec, nextvec))

        kernels = {}
        spikes = {}
        tdfs = {}
        dms = {}
        # Generate random kernels for stim and fdbk with random # of gaussians
        stimkernL = kerngen()
        stimkernR = kerngen()
        fdbkkern1 = kerngen()
        fdbkkern2 = kerngen()
        priorgain = rng.uniform(low=2, high=8)

        kernels = [stimkernL, stimkernR, fdbkkern1, fdbkkern2, priorgain]
        spikes = {}
        tdfs = {}
        dms = {}
        for linear in (True, False):
            scale = 1 if not linear else LINEAR_KERN_SCALE
            retlist = simulate_cell((stimkernL * scale, stimkernR * scale),
                                    (fdbkkern1 * scale, fdbkkern2 * scale),
                                    priorgain if linear else np.log(priorgain),
                                    GAIN if linear else np.log(GAIN),
                                    num_trials=NTRIALS, linear=linear)
            adj_spkt, trialsdf = concat_simcell_data(*retlist[:6])
            spikes[linear] = np.sort(adj_spkt)
            tdfs[linear] = trialsdf
            design = dm.DesignMatrix(trialsdf, vartypes, binwidth=BINSIZE)
            design.add_covariate_timing('stimL', 'stimOn_times', bases,
                                        cond=lambda tr: tr.contrasts > 0,
                                        deltaval='contrasts')
            design.add_covariate_timing('stimR', 'stimOn_times', bases,
                                        cond=lambda tr: tr.contrasts <= 0,
                                        deltaval='contrasts')
            design.add_covariate_timing('corr', 'feedback_times', bases,
                                        cond=lambda tr: tr.feedback_type == 1)
            design.add_covariate_timing('incorr', 'feedback_times', bases,
                                        cond=lambda tr: tr.feedback_type == -1)
            design.add_covariate_raw('biasfun', stepfunc_bias)
            design.compile_design_matrix()
            dms[linear] = design

        # Store into class for testing with GLM
        self.kernels = kernels
        self.spikes = spikes
        self.tdfs = tdfs
        self.dms = dms

    def test_poisson_GLM(self):
        # Fit a GLM to the data with a single kernel beginning at stim onset
        if not hasattr(self, 'fitw'):
            self.fitw = {}
        linear = False
        spikes = self.spikes[linear]
        design = self.dms[linear]
        nm = pm.PoissonGLM(design, spikes, np.ones_like(spikes, dtype=int), train=1.)
        nm.fit()
        comb = nm.combine_weights()
        self.fitw[linear] = comb
        for i, kern in enumerate(['stimL', 'stimR', 'corr', 'incorr']):
            scale = LINEAR_KERN_SCALE if linear else 1
            # Skip the last element of kernel until I figure out why the hell the models
            # Always fuck up the last time bin
            orig = self.kernels[i][:-1] * scale
            inferred = comb[kern].loc[1].iloc[:-1]
            ang = getang(orig, inferred)
            self.assertLess(ang, 15, "Large deviation between inferred "
                            f"Poisson model weight and generative kernel on {kern}")
    
    def test_linear_model(self):
        if not hasattr(self, 'fitw'):
            self.fitw = {}
        linear = True
        spikes = self.spikes[linear]
        design = self.dms[linear]
        nm = lm.LinearGLM(design, spikes, np.ones_like(spikes, dtype=int), train=1.)
        nm.fit()
        comb = nm.combine_weights()
        self.fitw[linear] = comb
        for i, kern in enumerate(['stimL', 'stimR', 'corr', 'incorr']):
            scale = LINEAR_KERN_SCALE if linear else 1
            # Skip the last element of kernel until I figure out why the hell the models
            # Always fuck up the last time bin
            orig = self.kernels[i][:-1] * scale
            inferred = comb[kern].loc[1].iloc[:-1]
            ang = getang(orig, inferred)
            self.assertLess(ang, 15, "Large deviation between inferred "
                            f"Linear model weight and generative kernel on {kern}")

def _generate_pseudo_blocks(n_trials, factor=60, min_=20, max_=100):
    block_ids = []
    while len(block_ids) < n_trials:
        x = rng.exponential(factor)
        while (x <= min_) | (x >= max_):
            x = rng.exponential(factor)
        if (len(block_ids) == 0) & (rng.integers(2) == 0):
            block_ids += [0] * int(x)
        elif (len(block_ids) == 0):
            block_ids += [1] * int(x)
        elif block_ids[-1] == 0:
            block_ids += [1] * int(x)
        elif block_ids[-1] == 1:
            block_ids += [0] * int(x)
    return np.array(block_ids[:n_trials])


def kerngen():
    weights = rng.uniform(low=-2, high=2, size=NBASES)
    return bases @ weights


def getang(a, b):
    prod = a @ b
    norms = np.linalg.norm(a) * np.linalg.norm(b)
    return np.arccos(prod / norms)


def simulate_cell(stimkerns, fdbkkerns, pgain, gain,
                  num_trials=500, linear=False, ret_raw=False):
    # all stim times are 400ms after trial start. Feedback t are drawn from static RT dist
    stimtimes = np.ones(num_trials) * 0.4
    fdbktimes = rng.choice(rt_vals, size=num_trials, p=rt_probs) \
        + stimtimes + rng.normal(size=num_trials) * 0.05
    priorbool = _generate_pseudo_blocks(num_trials)
    priors = np.array([{1: 0.2, 0: 0.8}[x] for x in priorbool])  # Map priors
    # Generate trial side and contrast
    contrasts = np.zeros_like(priors)
    pmask = priors == 0.8
    lowsigns = rng.choice([-1, 1], size=(~pmask).sum(), p=[0.2, 0.8])
    highsigns = rng.choice([-1, 1], size=pmask.sum(), p=[0.8, 0.2])
    contrasts = rng.choice(contrastvals, replace=True, size=num_trials)
    contrasts[pmask] *= highsigns
    contrasts[~pmask] *= lowsigns
    feedbacktypes = rng.choice([-1, 1], size=num_trials, p=[0.1, 0.9])
    trialspikes = []
    trialrates = []
    if ret_raw:
        trialcont = []
    trialrange = range(num_trials)
    zipiter = zip(trialrange, stimtimes, fdbktimes, priors,
                  contrasts, feedbacktypes)
    for i, start, end, prior, contrast, feedbacktype in zipiter:
        if i == (len(priors) - 1):
            continue
        trial_len = int(np.ceil((end + KERNLEN) / BINSIZE))
        stimarr = np.zeros(trial_len)
        fdbkarr = np.zeros(trial_len)
        stimarr[int(np.ceil(start / BINSIZE))] = 1
        fdbkarr[int(np.ceil(end / BINSIZE))] = 1
        stimkern = stimkerns[0] if contrast > 0 else stimkerns[1]
        fdbkkern = fdbkkerns[0] if feedbacktype == 1 else fdbkkerns[1]
        stimarr = np.convolve(stimkern, stimarr)[:trial_len] * contrast
        fdbkarr = np.convolve(fdbkkern, fdbkarr)[:trial_len]
        fdbkind = int(np.ceil(end / BINSIZE))

        priorarr = np.array([prior] * fdbkind +
                            [priors[i + 1]] * (trial_len - fdbkind))
        priorarr = pgain * priorarr
        kernsum = priorarr + stimarr + fdbkarr
        if not linear:
            ratevals = np.exp(kernsum + gain) * BINSIZE
            spikecounts = rng.poisson(ratevals)
        else:
            ratevals = (kernsum + gain) * BINSIZE
            contspikecounts = rng.normal(loc=ratevals, scale=gain * BINSIZE)
            spikecounts = np.round(contspikecounts).astype(int)
        if ret_raw:
            trialcont.append(contspikecounts)
        spike_times = []

        noisevals = rng.uniform(low=0, high=BINSIZE - 1e-6, size=np.max(spikecounts))
        for i in np.nonzero(spikecounts)[0]:
            curr_t = i * BINSIZE
            for j in range(spikecounts[i]):
                jitterspike = curr_t + noisevals[j]
                if jitterspike < 0:
                    jitterspike = 0
                spike_times.append(jitterspike)
        trialspikes.append(spike_times)
        trialrates.append(ratevals)
    retlist = [trialspikes, contrasts, priors, stimtimes,
               fdbktimes, feedbacktypes, trialrates,
               trialcont if ret_raw else None]
    return retlist


def concat_simcell_data(trialspikes, contrasts, priors, stimtimes, fdbktimes, feedbacktypes):
    trialsdf = pd.DataFrame()
    trialends = np.cumsum(fdbktimes + KERNLEN)
    trialends = np.pad(trialends, ((1, 0)), constant_values=0)
    cat_stimtimes = np.array(
        [trialends[i] + st for i, st in enumerate(stimtimes)])
    cat_fdbktimes = np.array(
        [trialends[i] + ft for i, ft in enumerate(fdbktimes)])
    trialsdf['contrasts'] = contrasts
    trialsdf['bias'] = priors
    trialsdf['bias_next'] = np.pad(priors[1:], (0, 1), constant_values=0)
    trialsdf['trial_start'] = trialends[:-1]
    trialsdf['trial_end'] = trialends[1:]
    trialsdf['stimOn_times'] = cat_stimtimes
    trialsdf['feedback_times'] = cat_fdbktimes
    trialsdf['feedback_type'] = feedbacktypes

    indices = trialsdf.index
    adj_spkt = np.hstack([trialsdf.loc[i].trial_start + np.array(t)
                          for i, t in zip(indices, trialspikes)])
    return adj_spkt, trialsdf.iloc[:-1]


if __name__ == '__main__':
    unittest.main()
